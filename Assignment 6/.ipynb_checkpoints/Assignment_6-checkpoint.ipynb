{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lOOQFzaLGfDj"
   },
   "source": [
    "# Assignment 6: Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VfF9hXD8rHCj"
   },
   "source": [
    "\n",
    "## 1. Backpropagation - Essentials\n",
    "\n",
    "As you examined in class, a simple layer in a feedforward neural network can be expressed as the following:\n",
    "\n",
    "$$h = Wx + b$$\n",
    "\n",
    "$$t = \\sigma(h)$$\n",
    "\n",
    "$$\\mathcal{L} = \\frac{1}{2}(y - t)^2$$\n",
    "\n",
    "where $x$ is the input, $W$ is the weight matrix at this node, $b$ is the bias added at the node, $\\sigma(\\cdot)$ is the activation function, $y$ is the label, and $\\mathcal{L}$ is the loss.\n",
    "\n",
    "The activation function and the loss function (squared loss used here) are choices made when creating a neural network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cZCyQV7cq8QC"
   },
   "source": [
    "\n",
    "### a. What are the unknowns in the problem?\n",
    "\n",
    "TODO:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zmhZZB-MrJm2"
   },
   "source": [
    "### b. What do we want minimize?\n",
    "\n",
    "TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4puUavw0rJpi"
   },
   "source": [
    "### c. What method could we use to find the unknowns?\n",
    "\n",
    "TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KQqGliGnrJsc"
   },
   "source": [
    "### d. Find the partial derivatives of L with respect to the unknowns. \n",
    "\n",
    "Assume we use ReLU for the activation function.\n",
    "\n",
    "TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O-CJNg0ULjhz"
   },
   "source": [
    "## 2. Backpropogation\n",
    "\n",
    "A neural network is regarded as compositional, in that the output of one layer feeds in as the input to the next layer. Using the the same notation as above but ignoring the bias $b$ for simplicity:\n",
    "\n",
    "$$t = \\sigma_L(W_L \\sigma_{L-1}(...\\sigma_2(W_2 \\sigma_1(W_1x))...))$$\n",
    "\n",
    "Here $x$ is the original input data, and $t$ is the output of the neural network.\n",
    "\n",
    "Even more simply, we can look at each layer L:\n",
    "\n",
    "$$N_1\\rightarrow N_2\\rightarrow N_3\\rightarrow ... N_{L-1}\\rightarrow N_L $$\n",
    "\n",
    "The idea here is the same - we will need to solve for partial derivatives for each layer to set the unknowns. As the previous layer feeds into the next, you can only solve for a Jacobian (vector of partials) one wrt one layer down e.g. we can first solve for\n",
    "\n",
    "$$ J_{N_L} (N_{L-1})$$\n",
    "\n",
    "the Jacobian of $N_L$ with respect to $N_{L-1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "INe3vqUxq4pX"
   },
   "source": [
    "### a. For the above simple representation, write out the Jacobian of the the final layer with respect to the first layer.\n",
    "\n",
    "TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ob64ZbCArSM_"
   },
   "source": [
    "### b. Based on the equation you've described above, explain using time or space complexity why the best way to solve for the gradient in 2a. is to work backwards.\n",
    "\n",
    "TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AUTKSiDD8SAs"
   },
   "source": [
    "## 3. Simple Neural Network\n",
    "\n",
    "Here you'll try out writing a neural network for a simple classification problem. For full credit, the final test accuracy should be above 0.6.\n",
    "\n",
    "The dataset is of cell images from thin blood smear slides of segmented cells, with labels indicating the presence of malaria.\n",
    "\n",
    "Source: https://lhncbc.nlm.nih.gov/publication/pub9932\n",
    "\n",
    "Paper: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6544011/\n",
    "\n",
    "Some setup to start with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zs4mXkqFLil8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uq7I0wsXBTIp"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'enable_eager_execution'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-ddf3115bdcc7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_eager_execution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'enable_eager_execution'"
     ]
    }
   ],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HzzpqV3R8znJ"
   },
   "outputs": [
    {
     "ename": "DatasetNotFoundError",
     "evalue": "Dataset malaria not found. Available datasets:\n\t- abstract_reasoning\n\t- aflw2k3d\n\t- amazon_us_reviews\n\t- bair_robot_pushing_small\n\t- bigearthnet\n\t- binarized_mnist\n\t- binary_alpha_digits\n\t- caltech101\n\t- caltech_birds2010\n\t- caltech_birds2011\n\t- cats_vs_dogs\n\t- celeb_a\n\t- celeb_a_hq\n\t- chexpert\n\t- cifar10\n\t- cifar100\n\t- cifar10_corrupted\n\t- clevr\n\t- cnn_dailymail\n\t- coco\n\t- coco2014\n\t- coil100\n\t- colorectal_histology\n\t- colorectal_histology_large\n\t- curated_breast_imaging_ddsm\n\t- cycle_gan\n\t- deep_weeds\n\t- definite_pronoun_resolution\n\t- diabetic_retinopathy_detection\n\t- downsampled_imagenet\n\t- dsprites\n\t- dtd\n\t- dummy_dataset_shared_generator\n\t- dummy_mnist\n\t- emnist\n\t- eurosat\n\t- fashion_mnist\n\t- flores\n\t- food101\n\t- gap\n\t- glue\n\t- groove\n\t- higgs\n\t- horses_or_humans\n\t- image_label_folder\n\t- imagenet2012\n\t- imagenet2012_corrupted\n\t- imdb_reviews\n\t- iris\n\t- kitti\n\t- kmnist\n\t- lfw\n\t- lm1b\n\t- lsun\n\t- mnist\n\t- mnist_corrupted\n\t- moving_mnist\n\t- multi_nli\n\t- nsynth\n\t- omniglot\n\t- open_images_v4\n\t- oxford_flowers102\n\t- oxford_iiit_pet\n\t- para_crawl\n\t- patch_camelyon\n\t- pet_finder\n\t- quickdraw_bitmap\n\t- resisc45\n\t- rock_paper_scissors\n\t- rock_you\n\t- scene_parse150\n\t- shapes3d\n\t- smallnorb\n\t- snli\n\t- so2sat\n\t- squad\n\t- stanford_dogs\n\t- stanford_online_products\n\t- starcraft_video\n\t- sun397\n\t- super_glue\n\t- svhn_cropped\n\t- ted_hrlr_translate\n\t- ted_multi_translate\n\t- tf_flowers\n\t- titanic\n\t- trivia_qa\n\t- uc_merced\n\t- ucf101\n\t- visual_domain_decathlon\n\t- voc2007\n\t- wikipedia\n\t- wmt14_translate\n\t- wmt15_translate\n\t- wmt16_translate\n\t- wmt17_translate\n\t- wmt18_translate\n\t- wmt19_translate\n\t- wmt_t2t_translate\n\t- wmt_translate\n\t- xnli\nCheck that:\n    - the dataset name is spelled correctly\n    - dataset class defines all base class abstract methods\n    - dataset class is not in development, i.e. if IN_DEVELOPMENT=True\n    - the module defining the dataset class is imported\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDatasetNotFoundError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-573eb2c23fcd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmalaria\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"malaria\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"train\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwith_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmalaria\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmalaria\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprefetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_datasets\\core\\api_utils.py\u001b[0m in \u001b[0;36mdisallow_positional_args_dec\u001b[1;34m(fn, instance, args, kwargs)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[0m_check_no_positional\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mismethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallowed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallowed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0m_check_required\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mdisallow_positional_args_dec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=no-value-for-parameter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_datasets\\core\\registered.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(name, split, data_dir, batch_size, in_memory, shuffle_files, download, as_supervised, decoders, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs)\u001b[0m\n\u001b[0;32m    295\u001b[0m     \u001b[0mdata_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconstants\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 297\u001b[1;33m   \u001b[0mdbuilder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuilder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mbuilder_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    298\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mdownload\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m     \u001b[0mdownload_and_prepare_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdownload_and_prepare_kwargs\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_datasets\\core\\registered.py\u001b[0m in \u001b[0;36mbuilder\u001b[1;34m(name, **builder_init_kwargs)\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mDatasetNotFoundError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_development\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_DATASET_REGISTRY\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mDatasetNotFoundError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_DATASET_REGISTRY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mbuilder_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDatasetNotFoundError\u001b[0m: Dataset malaria not found. Available datasets:\n\t- abstract_reasoning\n\t- aflw2k3d\n\t- amazon_us_reviews\n\t- bair_robot_pushing_small\n\t- bigearthnet\n\t- binarized_mnist\n\t- binary_alpha_digits\n\t- caltech101\n\t- caltech_birds2010\n\t- caltech_birds2011\n\t- cats_vs_dogs\n\t- celeb_a\n\t- celeb_a_hq\n\t- chexpert\n\t- cifar10\n\t- cifar100\n\t- cifar10_corrupted\n\t- clevr\n\t- cnn_dailymail\n\t- coco\n\t- coco2014\n\t- coil100\n\t- colorectal_histology\n\t- colorectal_histology_large\n\t- curated_breast_imaging_ddsm\n\t- cycle_gan\n\t- deep_weeds\n\t- definite_pronoun_resolution\n\t- diabetic_retinopathy_detection\n\t- downsampled_imagenet\n\t- dsprites\n\t- dtd\n\t- dummy_dataset_shared_generator\n\t- dummy_mnist\n\t- emnist\n\t- eurosat\n\t- fashion_mnist\n\t- flores\n\t- food101\n\t- gap\n\t- glue\n\t- groove\n\t- higgs\n\t- horses_or_humans\n\t- image_label_folder\n\t- imagenet2012\n\t- imagenet2012_corrupted\n\t- imdb_reviews\n\t- iris\n\t- kitti\n\t- kmnist\n\t- lfw\n\t- lm1b\n\t- lsun\n\t- mnist\n\t- mnist_corrupted\n\t- moving_mnist\n\t- multi_nli\n\t- nsynth\n\t- omniglot\n\t- open_images_v4\n\t- oxford_flowers102\n\t- oxford_iiit_pet\n\t- para_crawl\n\t- patch_camelyon\n\t- pet_finder\n\t- quickdraw_bitmap\n\t- resisc45\n\t- rock_paper_scissors\n\t- rock_you\n\t- scene_parse150\n\t- shapes3d\n\t- smallnorb\n\t- snli\n\t- so2sat\n\t- squad\n\t- stanford_dogs\n\t- stanford_online_products\n\t- starcraft_video\n\t- sun397\n\t- super_glue\n\t- svhn_cropped\n\t- ted_hrlr_translate\n\t- ted_multi_translate\n\t- tf_flowers\n\t- titanic\n\t- trivia_qa\n\t- uc_merced\n\t- ucf101\n\t- visual_domain_decathlon\n\t- voc2007\n\t- wikipedia\n\t- wmt14_translate\n\t- wmt15_translate\n\t- wmt16_translate\n\t- wmt17_translate\n\t- wmt18_translate\n\t- wmt19_translate\n\t- wmt_t2t_translate\n\t- wmt_translate\n\t- xnli\nCheck that:\n    - the dataset name is spelled correctly\n    - dataset class defines all base class abstract methods\n    - dataset class is not in development, i.e. if IN_DEVELOPMENT=True\n    - the module defining the dataset class is imported\n"
     ]
    }
   ],
   "source": [
    "malaria, info = tfds.load(name=\"malaria\", split=\"train\", with_info=True)\n",
    "malaria = malaria.shuffle(30000).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OmwQyvP1ZVbY"
   },
   "outputs": [],
   "source": [
    "# Visualize some images\n",
    "plt.figure(figsize=(12,12))\n",
    "\n",
    "for i, feature in enumerate(malaria.take(4)):\n",
    "    image = feature[\"image\"].numpy()\n",
    "    label = feature[\"label\"].numpy()\n",
    "    \n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.title(\"Label: \"+str(label))\n",
    "    plt.imshow(image)\n",
    "    # i+=1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i0WZhx66eFRc"
   },
   "source": [
    "### a. Extract some samples from the malaria dataset\n",
    "\n",
    "Hints:\n",
    "\n",
    "* Keep the total number of samples small ( < 10000) - it largely depends on your memory (if your notebook starts to crash, reduce the number of samples and try again)\n",
    "* The dimension of each image is height * width * 3, with the 3 representing the number of channels \n",
    "* The height and width of the images aren't all the same, so resize all of them to be 133 by 133 (see [tf.image.resize](https://www.tensorflow.org/api_docs/python/tf/image/resize))\n",
    "* The possibles labels are 0s and 1s (scalars)\n",
    "* Split into a training and testing set (a split like 80:20 train to test is reasonable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nDuTcN2eRqEN"
   },
   "outputs": [],
   "source": [
    "# TODO: Initialize to the correct shapes with zeros\n",
    "train_images = ...\n",
    "train_labels = ...\n",
    "test_images = ...\n",
    "test_labels = ...\n",
    "\n",
    "# TODO: Fill in the splits above\n",
    "total_sample_size = ...\n",
    "for i, feature in enumerate(malaria.take(total_sample_size)):\n",
    "\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Skfa7gabhx5b"
   },
   "source": [
    "### b. Add some layers to the model\n",
    "\n",
    "Hints:\n",
    "\n",
    "*   See examples of layers in the Keras documentation: https://keras.io/layers/core/\n",
    "*   For the first layer, provide an input_shape, which refers to the shape of an image from your dataset\n",
    "\n",
    "See examples at https://www.tensorflow.org/tutorials\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h17G-glzL1CC"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "# TODO:\n",
    "model.add(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mTAuV-yclMMV"
   },
   "source": [
    "### c. Choose how to train the above model\n",
    "\n",
    "Pick an optimizer, loss function, and metric. If you choose something not covered in class, give a brief explanation and an advantage of your choice.\n",
    "\n",
    "*   Optimizers: https://keras.io/optimizers/\n",
    "*   Losses: https://keras.io/losses/\n",
    "*   Metrics: https://keras.io/metrics/\n",
    "\n",
    "### Reasoning:\n",
    "\n",
    "TODO:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hpNocMjLlMaj"
   },
   "outputs": [],
   "source": [
    "# TODO:\n",
    "opt = ...\n",
    "loss_func = ...\n",
    "metric = [\"...\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "11W_u7LUQ5dy"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=opt,\n",
    "              loss=loss_func,\n",
    "              metrics=metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-fugsI4Um2id"
   },
   "source": [
    "### d. Train the model\n",
    "\n",
    "Choose an appropriate number of epochs (Hint: try some different values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7Bx1MyQeS1t4"
   },
   "outputs": [],
   "source": [
    "# TODO:\n",
    "num_epochs = ...\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N90CFDZro1h8"
   },
   "source": [
    "### e. Evaluate based on the testing set\n",
    "\n",
    "Must be greater that 0.6 for full credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1gBWoFo-TQb6"
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yOEvDCH9pF1l"
   },
   "source": [
    "### f. Based on the above accuracies between the testing and training sets, did you overfit while training?\n",
    "\n",
    "TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ae1IXzi7qE_O"
   },
   "source": [
    "\n",
    "### g. (Extra Credit) Improve your model to achieve an accuracy of greater than 0.75 on the testing set."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment 6.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
